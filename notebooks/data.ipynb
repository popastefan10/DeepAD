{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from torchvision.io import read_image, write_png\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.deep_ad.config import Config\n",
    "from src.deep_ad.data.dagm_dataset import DAGMDatasetDev\n",
    "from src.deep_ad.image import intersection_over_union, TBBox, show_image_with_bboxes, show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration\n",
    "config = Config(root_dir=\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstruction CNN uses only defect-free patches so I need to prepare a dataset containing them. I will take a \n",
    "constant number of patches from each image from the raw dataset. According to the original paper, they cropped patches\n",
    "larger than 128x128 pixels in order to avoid border effects after applying random transforms. However, they didn't\n",
    "specify the size of the patches.\n",
    "\n",
    "For better training, I thought that patches taken from the same image need to cover as much details as possible, so \n",
    "overlappings should be minimized. Thus, the intersection over union between each pair of patches must not exceed a\n",
    "certain threshold.\n",
    "\n",
    "Patches obtained will be saved in a folder structure identical to that of the raw DAGM dataset. However, each patch will\n",
    "contain the name, id (integer from `0` to `patches_per_image - 1`) and the `x` and `y` coordinates of the top-left \n",
    "corner. This new dataset will be saved in a directory uniquely identified by its configuration parameters: ppi (patches\n",
    "per image) and patch size in pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existing patches should be deleted, as new ones might not overwrite them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"..\\data\\processed\\DAGM\\4_ppi_160px\" does not exist. Exiting.\n"
     ]
    }
   ],
   "source": [
    "patches_dir = os.path.join(config.DAGM_processed_dir, f\"{config.patches_per_image}_ppi_{config.raw_patch_size}px\")\n",
    "if not os.path.exists(patches_dir):\n",
    "    print(f\"Directory \\\"{patches_dir}\\\" does not exist. Exiting.\")\n",
    "else:\n",
    "    number_of_files = len(glob.glob(os.path.join(patches_dir, \"Class*\", \"Train\", \"*.png\")))\n",
    "    prompt = f\"Are you sure you want to delete {number_of_files} files inside \\\"{patches_dir}\\\"? (y/n) \"\n",
    "    response = input(prompt).strip().lower()\n",
    "    if response != \"y\":\n",
    "        print(\"Exiting.\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Deleting {number_of_files} files inside \\\"{patches_dir}\\\"...\"\n",
    "        )\n",
    "        shutil.rmtree(patches_dir)\n",
    "        print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load only defect-free images and crop a fixed number of patches from each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dagm_ds = DAGMDatasetDev(config.DAGM_raw_dir, type=\"Defect-free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "\tpatches_per_image: 4\n",
      "\traw_patch_size: 160\n",
      "\tpatches_iou_threshold: 0.5\n",
      "Will save patches to \"..\\data\\processed\\DAGM\\4_ppi_160px\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7004/7004 [01:14<00:00, 94.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated a total of 28016 patches.\n"
     ]
    }
   ],
   "source": [
    "patches_dir = os.path.join(config.DAGM_processed_dir, f\"{config.patches_per_image}_ppi_{config.raw_patch_size}px\")\n",
    "print(\"Config:\")\n",
    "print(f\"\\tpatches_per_image: {config.patches_per_image}\")\n",
    "print(f\"\\traw_patch_size: {config.raw_patch_size}\")\n",
    "print(f\"\\tpatches_iou_threshold: {config.patches_iou_threshold}\")\n",
    "print(f\"Will save patches to \\\"{patches_dir}\\\".\")\n",
    "\n",
    "# Create directories for each class\n",
    "for cls in dagm_ds.all_classes:\n",
    "    cls_patches_dir = os.path.join(patches_dir, f\"Class{cls}\", \"Train\")\n",
    "    if not os.path.exists(cls_patches_dir):\n",
    "        os.makedirs(cls_patches_dir)\n",
    "\n",
    "# Generate patches\n",
    "for i in tqdm(range(len(dagm_ds))):\n",
    "    image, label, cls, name = dagm_ds[i]\n",
    "    cls_patches_dir = os.path.join(patches_dir, f\"Class{cls}\", \"Train\")\n",
    "    patch_bboxes: list[TBBox] = []\n",
    "\n",
    "    for _ in range(config.patches_per_image):\n",
    "        # Keep generating random coordinates while iou is greater than threshold\n",
    "        while True:\n",
    "            top_left_x = np.random.randint(0, image.shape[1] - config.raw_patch_size + 1)\n",
    "            top_left_y = np.random.randint(0, image.shape[0] - config.raw_patch_size + 1)\n",
    "            bbox: TBBox = (\n",
    "                top_left_x,\n",
    "                top_left_y,\n",
    "                top_left_x + config.raw_patch_size - 1,\n",
    "                top_left_y + config.raw_patch_size - 1,\n",
    "            )\n",
    "            if np.all(\n",
    "                [intersection_over_union(bbox, bbox_) < config.patches_iou_threshold for bbox_ in patch_bboxes]\n",
    "            ):\n",
    "                patch_bboxes.append(bbox)\n",
    "                break\n",
    "\n",
    "    # Save the patches\n",
    "    for i, bbox in enumerate(patch_bboxes):\n",
    "        patch = image[bbox[1] : bbox[3] + 1, bbox[0] : bbox[2] + 1].unsqueeze(0)\n",
    "        patch_name = f\"{name}_{i}_{bbox[0]}_{bbox[1]}.png\"\n",
    "        patch_path = os.path.join(cls_patches_dir, patch_name)\n",
    "        write_png(patch, patch_path)\n",
    "\n",
    "print(f\"Generated a total of {len(glob.glob(os.path.join(patches_dir, 'Class*', 'Train', '*.png')))} patches.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display an image and its bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cls = 2\n",
    "image_name = \"0577\"\n",
    "patches_dir = os.path.join(\n",
    "    config.DAGM_processed_dir, f\"{config.patches_per_image}_ppi_{config.raw_patch_size}px\", f\"Class{image_cls}\", \"Train\"\n",
    ")\n",
    "bboxes: list[TBBox] = []\n",
    "for i in range(config.patches_per_image):\n",
    "    patch_path = os.path.join(patches_dir, f\"{image_name}_{i}_*.png\")\n",
    "    patch_path = glob.glob(patch_path)[0]\n",
    "    tl_x = int(patch_path.split(\"_\")[-2])\n",
    "    tl_y = int(patch_path.split(\"_\")[-1].split(\".\")[0])\n",
    "    bboxes.append((tl_x, tl_y, tl_x + config.raw_patch_size - 1, tl_y + config.raw_patch_size - 1))\n",
    "\n",
    "image = (\n",
    "    read_image(os.path.join(config.DAGM_raw_dir, f\"Class{image_cls}\", \"Train\", f\"{image_name}.png\")).squeeze(0).numpy()\n",
    ")\n",
    "show_image_with_bboxes(image, bboxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
